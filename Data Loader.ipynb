{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "\n",
    "It'll make things look a bit cleaner to load the data in a separate script from the report generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Import all the things!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import geopy\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from IPython.display import HTML, Markdown, clear_output\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import urllib3\n",
    "\n",
    "%run controls.ipynb\n",
    "\n",
    "# Step 1: Download a copy of the web page that contains the data I want.\n",
    "\n",
    "# The state's SSL certificate is expired; I'm going to ignore that particular problem.\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "response = requests.get(\"https://dshs.texas.gov/news/updates.shtm\", verify=False)\n",
    "source = BeautifulSoup(response.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3500d25db5fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcounty_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"summary\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"summary\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"COVID-19 Cases in Texas Counties\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrow_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"td\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounty_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Step 2: Grab the <table> out of the page and turn it into a DataFrame.\n",
    "\n",
    "tables = source.find_all(\"table\")\n",
    "county_table = [t for t in tables if t.has_attr(\"summary\") and t.attrs[\"summary\"] == \"COVID-19 Cases in Texas Counties\"][0]\n",
    "\n",
    "row_groups = [tr.find_all(\"td\") for tr in county_table.find_all(\"tr\")][1:]\n",
    "\n",
    "today = dt.datetime.today()\n",
    "today_text = f\"{today.month}/{today.day}/{today.year}\"\n",
    "\n",
    "num_cases = [{\n",
    "    \"county\": td[0].text,\n",
    "    \"date\": today_text,\n",
    "    \"num_cases\": td[1].text\n",
    "} for td in row_groups]\n",
    "\n",
    "df_num_cases = pd.DataFrame(num_cases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Add the latitude and longitude to each row.\n",
    "\n",
    "locator = geopy.Nominatim(user_agent=\"myGeocoder\")\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=0.1)\n",
    "\n",
    "df_num_cases[\"point\"] = (df_num_cases[\"county\"] + \", TX\").apply(geocode)\n",
    "\n",
    "# I am substituting (28.082612, -94.936773) for the *official* coordinates of the Gulf of Mexico to better position it on the map.\n",
    "df_num_cases[['latitude', 'longitude']] = pd.DataFrame([\n",
    "    (p.latitude, p.longitude) if p != None else (28.082612, -94.936773) # list(locator.geocode(\"Gulf of Mexico\"))[1]\n",
    "    for p in df_num_cases[\"point\"].tolist()])\n",
    "df_num_cases = df_num_cases.drop([\"point\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Concatenate today's data with the full dataset.\n",
    "# TODO: Running this more than once will add duplicates to the data.  I can make this nicer by performing some kind of distinct() function on the data.\n",
    "\n",
    "df_num_cases = pd.concat([pd.read_csv(\"data.csv\"), df_num_cases])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Save the new dataset.\n",
    "\n",
    "df_num_cases.columns = [\"unnamed\", \"county\", \"date\", \"num_cases\", \"latitude\", \"longitude\"]\n",
    "df_num_cases = df_num_cases.drop(columns=[\"unnamed\"], axis=1)\n",
    "\n",
    "# TODO: Always make a backup before running this.\n",
    "df_num_cases.to_csv(\"data.csv\")\n",
    "\n",
    "# Now we are ready to play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
