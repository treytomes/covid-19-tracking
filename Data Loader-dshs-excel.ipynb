{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "\n",
    "It'll make things look a bit cleaner to load the data in a separate script from the report generator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Import all the things!\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import geopy\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from IPython.display import HTML, Markdown, clear_output\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import urllib3\n",
    "import re\n",
    "\n",
    "%run controls.ipynb\n",
    "\n",
    "def datestamp(date):\n",
    "    \"\"\"Convert a datetime object into a date stamp: MM/DD/YYYY\"\"\"\n",
    "    return f\"{date.month}/{date.day}/{date.year}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Download a copy of the web page that contains the data I want.\n",
    "\n",
    "The state has moved to an arcgis data source.  Looks a lot nicer than an html table, but it's also harder to scrape.  I'll try to figure out how to connect to that data later, but I was able to copy and paste this text from here: https://txdshs.maps.arcgis.com/apps/opsdashboard/index.html#/ed483ecd702b4298ab01e8b9cafc8b83\n",
    "\n",
    "5/10/20: Download this spreadsheet instead: https://dshs.texas.gov/coronavirus/TexasCOVID19CaseCountData.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COVID-19 Cases and Fatalities by County as of 5/14 at 10:45AM CST'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data refresh date: 2020-05-14 10:45:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Cases</th>\n",
       "      <th>Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anderson</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrews</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angelina</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aransas</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Archer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Wood</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Yoakum</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Young</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Zapata</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Zavala</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       County  Cases  Fatalities\n",
       "0    Anderson     51           0\n",
       "1     Andrews     22           0\n",
       "2    Angelina    119           1\n",
       "3     Aransas      3           0\n",
       "4      Archer      0           0\n",
       "..        ...    ...         ...\n",
       "249      Wood     15           0\n",
       "250    Yoakum      2           0\n",
       "251     Young      4           1\n",
       "252    Zapata      7           0\n",
       "253    Zavala      9           0\n",
       "\n",
       "[254 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YEAR = 2020\n",
    "\n",
    "# The state's SSL certificate is expired; I'm going to ignore that particular problem.\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "filename = \"TexasCOVID19CaseCountData.xlsx\"\n",
    "\n",
    "url = \"https://dshs.texas.gov/coronavirus/TexasCOVID19CaseCountData.xlsx\"\n",
    "connection_pool = urllib3.PoolManager(cert_reqs='CERT_NONE', assert_hostname=False)\n",
    "resp = connection_pool.request('GET',url )\n",
    "f = open(filename, 'wb')\n",
    "f.write(resp.data)\n",
    "f.close()\n",
    "resp.release_conn()\n",
    "\n",
    "title = pd.read_excel(filename).columns.values[0]\n",
    "display(title)\n",
    "\n",
    "match = re.search(\"(?P<month>\\d)/(?P<day>\\d{2})\", title)\n",
    "if match is None:\n",
    "    raise Exception(\"Something is wrong with the spreadsheet.\")\n",
    "\n",
    "month = int(match[\"month\"])\n",
    "day = int(match[\"day\"])\n",
    "\n",
    "match = re.search(\"(?P<hour>\\d{2}):(?P<minute>\\d{2})(?P<ampm>\\w{2})\", title)\n",
    "if match is None:\n",
    "    raise Exception(\"Something is wrong with the spreadsheet.\")\n",
    "\n",
    "hour = int(match[\"hour\"])\n",
    "minute = int(match[\"minute\"])\n",
    "if (match[\"ampm\"] == \"PM\") and (hour > 12):\n",
    "    hour += 12\n",
    "\n",
    "date = dt.datetime(YEAR, month, day, hour, minute)\n",
    "    \n",
    "print(f\"Data refresh date: {date}\")\n",
    "if date.date() != dt.datetime.today().date():\n",
    "    raise Exception(\"The data isn't ready yet.\")\n",
    "\n",
    "df = pd.read_excel(filename, sheet_name=\"Case and Fatalities\", header=1, skipfooter=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Clean up the text I copied and convert it into a proper DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>date</th>\n",
       "      <th>num_cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anderson</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrews</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angelina</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aransas</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Archer</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Wood</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Yoakum</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Young</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Zapata</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Zavala</td>\n",
       "      <td>5/14/2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       county       date  num_cases\n",
       "0    Anderson  5/14/2020         51\n",
       "1     Andrews  5/14/2020         22\n",
       "2    Angelina  5/14/2020        119\n",
       "3     Aransas  5/14/2020          3\n",
       "4      Archer  5/14/2020          0\n",
       "..        ...        ...        ...\n",
       "249      Wood  5/14/2020         15\n",
       "250    Yoakum  5/14/2020          2\n",
       "251     Young  5/14/2020          4\n",
       "252    Zapata  5/14/2020          7\n",
       "253    Zavala  5/14/2020          9\n",
       "\n",
       "[254 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "today = dt.datetime.today()\n",
    "today_text = datestamp(today)\n",
    "\n",
    "df[\"date\"] = today_text\n",
    "df[\"num_cases\"] = df[\"Cases\"]\n",
    "\n",
    "df = df.drop(columns=[\"Cases\", \"Fatalities\"], axis=1)\n",
    "df.columns = [ \"county\", \"date\", \"num_cases\" ]\n",
    "\n",
    "df_num_cases = df\n",
    "display(df_num_cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Add the latitude and longitude to each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = geopy.Nominatim(user_agent=\"myGeocoder\")\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
    "\n",
    "df_counties = pd.read_csv(\"county_coords.csv\")\n",
    "\n",
    "def get_coordinates(county_name):\n",
    "    global df_counties\n",
    "    exists = len(df_counties.loc[df_counties[\"county\"] == county_name]) != 0\n",
    "    if exists:\n",
    "        return [{\"latitude\":r[0], \"longitude\":r[1]} for r in df_counties.loc[df_counties[\"county\"] == county_name][[\"latitude\", \"longitude\"]].values][0]\n",
    "    else:\n",
    "        point = geocode(county_name + \" County, TX\")\n",
    "        df_county = pd.DataFrame([[county_name, point.latitude, point.longitude]], columns=[\"county\", \"latitude\", \"longitude\"])\n",
    "        df_counties = df_counties.append(df_county)\n",
    "        return {\"latitude\":point.latitude, \"longitude\":point.longitude}\n",
    "\n",
    "df_num_cases[\"point\"] = (df_num_cases[\"county\"]).apply(get_coordinates) #geocode)\n",
    "##df_num_cases[\"point\"] = (df_num_cases[\"county\"]).apply(geocode)\n",
    "\n",
    "# I am substituting (28.082612, -94.936773) for the *official* coordinates of the Gulf of Mexico to better position it on the map.\n",
    "##df_num_cases[['latitude', 'longitude']] = pd.DataFrame([\n",
    "##    (p.latitude, p.longitude) if p != None else (28.082612, -94.936773) # list(locator.geocode(\"Gulf of Mexico\"))[1]\n",
    "##    for p in df_num_cases[\"point\"].tolist()])\n",
    "df_num_cases[['latitude', 'longitude']] = pd.DataFrame([\n",
    "    (p[\"latitude\"], p[\"longitude\"]) if p != None else (28.082612, -94.936773) # list(locator.geocode(\"Gulf of Mexico\"))[1]\n",
    "    for p in df_num_cases[\"point\"].tolist()])\n",
    "df_num_cases = df_num_cases.drop([\"point\"], axis=1)\n",
    "\n",
    "# Save the county coordinates to preserve any new data.\n",
    "df_counties.set_index(\"county\", inplace=True)\n",
    "df_counties.to_csv(\"county_coords.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Concatenate today's data with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Running this more than once will add duplicates to the data.  I can make this nicer by performing some kind of distinct() function on the data.\n",
    "\n",
    "df_num_cases = pd.concat([pd.read_csv(\"data.csv\"), df_num_cases])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Save the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_cases.columns = [\"unnamed\", \"county\", \"date\", \"num_cases\", \"latitude\", \"longitude\"]\n",
    "df_num_cases = df_num_cases.drop(columns=[\"unnamed\"], axis=1)\n",
    "\n",
    "# TODO: Always make a backup before running this.\n",
    "df_num_cases.to_csv(\"data.csv\")\n",
    "\n",
    "# Now we are ready to play with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Make the dates text-sortable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk of code will fix the date column to make it text-sortable, by zero-padding the pieces of the date.\n",
    "# If this virus continues into 2021 I will need to amend the date column to be YYYYMMDD instead of MM/DD/YYYY.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def fix_date(date_text):\n",
    "    pieces = date_text.split(\"/\")\n",
    "    pieces[0] = pieces[0].zfill(2)\n",
    "    pieces[1] = pieces[1].zfill(2)\n",
    "    pieces[2] = pieces[2].zfill(2)\n",
    "    return pieces[0] + \"/\" + pieces[1] + \"/\" + pieces[2]\n",
    "\n",
    "df_data = pd.read_csv(\"data.csv\")\n",
    "df_data.columns = [\"unnamed\", \"county\", \"date\", \"num_cases\", \"latitude\", \"longitude\"]\n",
    "df_data = df_data.drop(columns=[\"unnamed\"], axis=1)\n",
    "\n",
    "df_data[\"date\"] = df_data[\"date\"].apply(fix_date)\n",
    "\n",
    "df_data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This bit will swap out 2 days; important if I load the data the morning after.\n",
    "\n",
    "return\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "old_date = \"05/11/2020\"\n",
    "new_date = \"05/10/2020\"\n",
    "\n",
    "def fix_date(date_text):\n",
    "    if date_text == old_date:\n",
    "        return new_date\n",
    "    else:\n",
    "        return date_text\n",
    "\n",
    "df_data = pd.read_csv(\"data.csv\")\n",
    "df_data.columns = [\"unnamed\", \"county\", \"date\", \"num_cases\", \"latitude\", \"longitude\"]\n",
    "df_data = df_data.drop(columns=[\"unnamed\"], axis=1)\n",
    "\n",
    "df_data[\"date\"] = df_data[\"date\"].apply(fix_date)\n",
    "\n",
    "df_data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyodbc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-efb102f3af7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlalchemy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyodbc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyodbc'"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "import sqlalchemy as db\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "%reload_ext sql\n",
    "\n",
    "%sql mssql+pyodbc://Trey:elliott0!@47.222.182.190:1433/Covid19={sqlsrv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
